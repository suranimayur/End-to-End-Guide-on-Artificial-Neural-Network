{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHPXvQw++6d2XmieUpkWh+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suranimayur/End-to-End-Guide-on-Artificial-Neural-Network/blob/main/deep_learning_models_for_multi_output_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLX4dkjRq3O5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Deep-learning-models-for-multi-output-regression**"
      ],
      "metadata": {
        "id": "HHwoVGo8ruV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# example of a multi-output regression problem\n",
        "from sklearn.datasets import make_regression\n",
        "# create dataset\n",
        "X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, n_targets=3, random_state=2)\n",
        "# summarize shape\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz1-1I85rttj",
        "outputId": "62ef12c2-1533-41c0-9281-c7f9d15d90a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1000, 10) (1000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN8Z9N3aq_WU",
        "outputId": "5e159799-505e-4580-e003-3047b5ed05d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.99859353  2.19284309 -0.42632569 ... -0.87625098 -0.99445578\n",
            "  -0.3677487 ]\n",
            " [-0.88621913  0.58261383  0.13903253 ...  0.77270374  0.64154002\n",
            "  -1.13040409]\n",
            " [-0.66436784  0.27447937 -1.60099657 ... -1.19078841 -0.0367227\n",
            "  -0.54965583]\n",
            " ...\n",
            " [ 0.06468909  0.08012381 -1.3204591  ... -1.17063522  0.66082312\n",
            "   1.08846103]\n",
            " [-0.99720001 -0.5371702  -0.01041399 ... -0.05874157  0.63516738\n",
            "  -0.16871675]\n",
            " [ 0.05384091 -1.03029189 -1.13987039 ... -1.49285593  1.32674104\n",
            "   1.8478841 ]]\n",
            "[[-148.03723474  -80.63209848  -91.5736561 ]\n",
            " [ -82.27272654  -54.35420936 -114.40357938]\n",
            " [-160.04683144 -112.6928605   -78.47448648]\n",
            " ...\n",
            " [ -57.06470093   -3.65337026    5.37879727]\n",
            " [ -84.15214472  -28.85380227  -24.39982153]\n",
            " [ -28.32501715   35.58057957   93.02173732]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Neural Network for Multi-Outputs"
      ],
      "metadata": {
        "id": "vluGGPbxr8JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDe6syYesSH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define a multilayer perceptron (MLP) model for the multi-output regression task defined in the previous section.\n",
        "\n"
      ],
      "metadata": {
        "id": "d18PKHpVsenW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "poyPAu5Bsfkp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define a multilayer perceptron (MLP) model for the multi-output regression task defined in the previous section.\n",
        "\n",
        "Each sample has 10 inputs and three outputs, therefore, the network requires an input layer that expects 10 inputs specified via the “input_dim” argument in the first hidden layer and three nodes in the output layer.\n",
        "\n",
        "We will use the popular ReLU activation function in the hidden layer. The hidden layer has 20 nodes, which were chosen after some trial and error. We will fit the model using mean absolute error (MAE) loss and the Adam version of stochastic gradient descent."
      ],
      "metadata": {
        "id": "keujdwZjs_T9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### The definition of the network for the multi-output regression task is listed below.\n",
        "\n"
      ],
      "metadata": {
        "id": "FcnDuacrs_5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "91AkAl5ozKtN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(20, input_dim=10, kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(Dense(3))\n",
        "model.compile(loss='mae', optimizer='adam')"
      ],
      "metadata": {
        "id": "FeyYhjObtEMd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may want to adapt this model for your own multi-output regression task, therefore, we can create a function to define and return the model where the number of input and number of output variables are provided as arguments."
      ],
      "metadata": {
        "id": "EZVjBHL8zut5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# get the model\n",
        "def get_model(n_inputs, n_outputs):\n",
        " model = Sequential()\n",
        " model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
        " model.add(Dense(n_outputs))\n",
        " model.compile(loss='mae', optimizer='adam')\n",
        " return model"
      ],
      "metadata": {
        "id": "8g9IsExfzs18"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neural Network for Multi-Output Regression\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "vWgvu-apz9AQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, it is good practice to use k-fold cross-validation instead of train/test splits of a dataset to get an unbiased estimate of model performance when making predictions on new data. Again, only if there is not too much data and the process can be completed in a reasonable time."
      ],
      "metadata": {
        "id": "dnZH2iAa0NvV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fa4BoUk20SA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking this into account, we will evaluate the MLP model on the multi-output regression task using repeated k-fold cross-validation with 10 folds and three repeats.\n",
        "\n",
        "Each fold the model is defined, fit, and evaluated. The scores are collected and can be summarized by reporting the mean and standard deviation.\n",
        "\n",
        "The evaluate_model() function below takes the dataset, evaluates the model, and returns a list of evaluation scores, in this case, MAE scores."
      ],
      "metadata": {
        "id": "RbCS-WNq0VEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# evaluate a model using repeated k-fold cross-validation\n",
        "def evaluate_model(X, y):\n",
        "  results = list()\n",
        "  n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
        "  # define evaluation procedure\n",
        "  cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  # enumerate folds\n",
        "  for train_ix, test_ix in cv.split(X):\n",
        "    # prepare data\n",
        "    X_train, X_test = X[train_ix], X[test_ix]\n",
        "    y_train, y_test = y[train_ix], y[test_ix]\n",
        "  # define model\n",
        "  model = get_model(n_inputs, n_outputs)\n",
        "  # fit model\n",
        "  model.fit(X_train, y_train, verbose=0, epochs=100)\n",
        "  # evaluate model on test set\n",
        "  mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "  # store result\n",
        "  print('>%.3f' % mae)\n",
        "  results.append(mae)\n",
        "  return results"
      ],
      "metadata": {
        "id": "CXZO4Rz60Vhp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp for multi-output regression\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        " "
      ],
      "metadata": {
        "id": "6VomGpb10qCZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the dataset\n",
        "def get_dataset():\n",
        "  X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, \\\n",
        "                         n_targets=3, random_state=2)\n",
        "  return X, y"
      ],
      "metadata": {
        "id": "PlnA-e0z1DEV"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the model\n",
        "def get_model(n_inputs, n_outputs):\n",
        "  model = Sequential()\n",
        "  model.add(Dense(20, input_dim=n_inputs, kernel_initializer='he_uniform', activation='relu'))\n",
        "  model.add(Dense(n_outputs))\n",
        "  model.compile(loss='mae', optimizer='adam')\n",
        "  return model"
      ],
      "metadata": {
        "id": "pHfW-nPH1Ljf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a model using repeated k-fold cross-validation\n",
        "def evaluate_model(X, y):\n",
        "  results = list()\n",
        "  n_inputs, n_outputs = X.shape[1], y.shape[1]\n",
        "  # define evaluation procedure\n",
        "  cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "  # enumerate folds\n",
        "  for train_ix, test_ix in cv.split(X):\n",
        "  # prepare data\n",
        "    X_train, X_test = X[train_ix], X[test_ix]\n",
        "    y_train, y_test = y[train_ix], y[test_ix]\n",
        "  # define model\n",
        "  \n",
        "  model = get_model(n_inputs, n_outputs)\n",
        "  # fit model\n",
        "  model.fit(X_train, y_train, verbose=0, epochs=100)\n",
        "  # evaluate model on test set\n",
        "  mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "  # store result\n",
        "  print('>%.3f' % mae)\n",
        "  results.append(mae)\n",
        "  return results"
      ],
      "metadata": {
        "id": "Ijr8xGhk1S-a"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "# load dataset\n",
        "X, y = get_dataset()\n",
        "# evaluate model\n",
        "results = evaluate_model(X, y)\n",
        "# summarize performance\n",
        "print('MAE: %.3f (%.3f)' % (mean(results), std(results)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUv4-3_92Wgn",
        "outputId": "06a3cb7a-70ff-4e8e-81e2-dca5432fddd0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">6.820\n",
            "MAE: 6.820 (0.000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mywv7vZg2Zny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}